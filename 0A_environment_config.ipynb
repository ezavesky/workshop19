{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of model installation.\n",
    "\n",
    "# ===============LICENSE_START=======================================================\n",
    "# Apache-2.0\n",
    "# ===================================================================================\n",
    "# Copyright (C) 2019 AT&T Intellectual Property  All rights reserved.\n",
    "# ===================================================================================\n",
    "# This software file is distributed by AT&T\n",
    "# under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# This file is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ===============LICENSE_END=========================================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Shared Computing\n",
    "With the advances in containerization and environment porting, it's gotten a lot easier to develop and debug from just about anywhere.  This workshop hopes to leverage those gains and will utilize [interactive notebooks](https://jupyter4edu.github.io/jupyter-edu-book/why-we-use-jupyter-notebooks.html) to demonstrate utilies and processes.\n",
    "\n",
    "## Starter Deployment (CMLP)\n",
    "Another advantage of web-based development is that you don't need to have a high-power local workstation.  Instead, utilizing a notebook server (or hub) installed within an enterprise, just point to the root, authenticate and you're ready to go.\n",
    "\n",
    "As of late March 2019, that's the approach made possible by a notebook server hosted by [CMLP](http://cmlp.web.att.com/) (common machine learning platform).  To utilize a notebook right now, follow these simple steps.\n",
    "\n",
    "1. Head to [CMLP](http://cmlp.web.att.com/)\n",
    "2. On the right side of the menu, click on `Workbench` and then `Jupyter`.  You can also try this [direct link](https://cmlp-portal.prod.sci.att.com/#/pages/jupyter) but it may not work if you haven't logged in before.\n",
    "3. Click on the button \"Launch Jupyter\"\n",
    "4. If you've launched it before, you'll jump right into a new jupyter notebook session, head to the next section called \"Install the Basics\"!\n",
    "5. If you're asked additional questions about creating a new environment, just accept the defaults and proceed.  In the worst case scenario, you will be presented with a loading screen for about 5 minutes while a new node is started.\n",
    "\n",
    "## Starter Deployment (local Jupyter)\n",
    "If you're starting from scratch on your own machine, there's a little more work to do -- but not much.  This workflow was pruned to just the basic, clear steps to get started.  Luckily, there are some great tutorials by the [Pinnacle](https://pinnacle.web.att.com/learn) project for setting up an approved environment or using [DewDrop VMs](https://wiki.web.att.com/x/y4TpOQ) if you would rather host things locally.  \n",
    "\n",
    "When you have a working conda environment, head to the next step to \"install the basics\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install the Basics\n",
    "The basics for automated software installation are really just [Anaconda](https://docs.anaconda.com/anaconda/install/) (a great simplification for package management) and [Jupyter](https://jupyter.org/install).  With these two configurations, you should be able to proceed to using actual scripts to do the hard work.\n",
    "\n",
    "## Clone or Copy the Source\n",
    "You're now ready to start working from the workshop's source code tree.  To do so, there are a couple of options.\n",
    "\n",
    "1. Log into [CodeCloud](https://codecloud.web.att.com/projects/ST_MLHACK19/repos/ml_workshop/browse) and clone the workshop's repo into your jupyter environment.\n",
    "> git clone ssh://git@codecloud.web.att.com:7999/st_mlhack19/ml_workshop.git\n",
    "2. Download a source/tar release of the code.  If you can access CodeCloud, it should just be a matter of [this download link](https://codecloud.web.att.com/rest/api/latest/projects/ST_MLHACK19/repos/ml_workshop/archive?format=zip) and then copying the file to your working jupyter environment.\n",
    "\n",
    "When you have the notebooks unzipped and ready to go, just start running the cells on the first file (this one) currently named `0A_envoronment_config.ipynb`.\n",
    "\n",
    "## Run the Cells Below\n",
    "Running a cell is as simple as clicking the play/run button.  Otherwise you can hit shift-enter on a single cell for it to be evaluated.\n",
    "\n",
    "The cells below will install additional [python packages](https://pypi.org/) or their often version-normalized [conda packages](https://anaconda.org/anaconda/repo) equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for internal AT&T users, you'll need to set a proxy so that you can fetch packages from afar\n",
    "import os\n",
    "os.environ[\"http_proxy\"] = \"http://one.proxy.att.com:8080\"\n",
    "os.environ[\"https_proxy\"] = \"http://one.proxy.att.com:8080\"\n",
    "\n",
    "# Okay, let's update your conda environment\n",
    "!conda install -c anaconda libprotobuf -y\n",
    "\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving the data\n",
    "Normally data retrieval and placement may be a little harder than this, but for now we'll just pull from an internal source in this script so that your evironment should be ready to go!  To learn more about these files and the dataset, check out the data/README.md file in this repo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the main \"reviews\" file\n",
    "!wget \"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Office_Products_10.json.gz\" -O \"data/reviews_Office_Products_10.json.gz\"\n",
    "\n",
    "# grab the main \"metadata\" file\n",
    "!wget \"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/meta_Office_Products.json.gz\" -O \"data/meta_Office_Products.json.gz\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Done!\n",
    "Not too bad, right? Well, this should now have all of the software packages you need to run the rest of the scripts in this demo.  Let's move on to the next notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
