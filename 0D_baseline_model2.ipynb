{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: Review Baseline Example\n",
    "Here, we will use all of the encoded data to create a new model using numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============LICENSE_START=======================================================\n",
    "# Apache-2.0\n",
    "# ===================================================================================\n",
    "# Copyright (C) 2019 AT&T Intellectual Property  All rights reserved.\n",
    "# ===================================================================================\n",
    "# This software file is distributed by AT&T\n",
    "# under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# This file is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ===============LICENSE_END=========================================================\n",
    "\n",
    "import pandas as pd  # data read\n",
    "from sklearn import preprocessing  # data ETL\n",
    "import os,sys  # file checks\n",
    "import dill as pickle   # serialize functions and data as compressed binary \n",
    "import gzip  # compression \n",
    "import yaml   # configuration file\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import util_review\n",
    "import util_train\n",
    "\n",
    "# for interactive graphs\n",
    "# %matplotlib notebook  \n",
    "\n",
    "config_path = 'config.yaml'\n",
    "if not os.path.isfile(config_path):\n",
    "    print(\"Sorry, can't find the configuration file {}, aborting.\".format(config_path))\n",
    "    sys.exit(-1)\n",
    "config = yaml.safe_load(open(config_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read our larger datasets as binary files\n",
    "with gzip.open(config[\"path\"][\"etl\"], 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "# read our intermediate model data (in case we need to transform again)\n",
    "with gzip.open(config[\"path\"][\"model_preproc\"], 'rb') as f:\n",
    "    etl = pickle.load(f)   # note that we use local variable 'etl' instead of 'models'\n",
    "    \n",
    "print(df.keys())\n",
    "print(\"Loaded Dimensionality: Training({}), RawTest({})\".format(\n",
    "    df[\"X_train\"].shape, df[\"X_test\"].shape ))\n",
    "print(df[\"X_train\"].columns)\n",
    "print(df[\"X_test\"].columns)\n",
    "\n",
    "df[\"X_train\"].sample(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing \n",
    "Preprocessing will run through required steps to generate extra columns and normalize (according to inputs) for the underlying predictors to train/evaluate a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the FUNCTION and a data example for later use!\n",
    "df[\"X_test_enc\"] = df[\"X_test\"].copy()\n",
    "df[\"X_test_enc\"] = etl[\"fn_preproc\"](etl, df[\"X_test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Evaluation\n",
    "This quick function will plot the performance of our algorithm by finding the [area under the curve (aka ROC)](https://en.wikipedia.org/wiki/Receiver_operating_characteristic).\n",
    "\n",
    "For basic models, a number of sample models from scikit are included as possibilities, like a [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) and or a [GradientBoostedClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier).  The model utilized is chosen by the configuration file setting `model_type`.\n",
    "\n",
    "A more advanced model training process is also included called [cross validation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html).  Here, we use cross validalidation to explore a number of parameter settings (and random starts) to find the best performing model configutation.  This option is also controlled in the configuration file by the parameter `cross_validate` but by default it is disabled because of the expected run time.\n",
    "\n",
    "Finally, we can use [error metrics](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter) (here [average_precision](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html) as determined by the config setting `scoring`) to more easily compare the performance of different models that we build.  It should be noted that no tunings for either model was done, so it doesn't speak to the overall fitness of one type versus another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "models = util_train.train_model(df[\"X_train\"], df[\"y_train\"], config[\"training\"][\"scoring\"], \n",
    "                                config[\"training\"][\"model_type\"], config[\"training\"][\"cross_validate\"], \n",
    "                                config[\"training\"][\"threads\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure Performance\n",
    "Evaluate performance of the newly trained model (saved under `models[\"best\"]`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print performance!\n",
    "auc_class, fig = util_review.draw_roc(df[\"X_test_enc\"], df[\"y_test\"], \n",
    "                                 classifier=models[\"best\"], \n",
    "                                 title=\"{} Review ROC\".format(config[\"training\"][\"model_type\"]))\n",
    "fig.savefig(config[\"path\"][\"figure_classifier\"])  # saves the current figure\n",
    "\n",
    "print(\"{} AUC: {:0.3f}, trained time: {:0.3f}s\".format(config[\"training\"][\"model_type\"], \n",
    "                                                       auc_class, models[\"time_train\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write created classifier\n",
    "Writes all classification data to compressed file object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, write out our intermediate data...\n",
    "# and write out our intermediate model data (in case we need to transform again)\n",
    "with gzip.open(config[\"path\"][\"model_classifier\"], 'wb') as f:\n",
    "    pickle.dump(models, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
