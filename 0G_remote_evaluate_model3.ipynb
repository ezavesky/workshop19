{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of simple model load and evaluate\n",
    "\n",
    "# ===============LICENSE_START=======================================================\n",
    "# Apache-2.0\n",
    "# ===================================================================================\n",
    "# Copyright (C) 2019 AT&T Intellectual Property  All rights reserved.\n",
    "# ===================================================================================\n",
    "# This software file is distributed by AT&T\n",
    "# under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# This file is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ===============LICENSE_END=========================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,sys,shutil  # file checks\n",
    "import dill as pickle   # serialize functions and data as compressed binary \n",
    "import gzip  # compression \n",
    "import yaml   # configuration file\n",
    "import time  # time tracking\n",
    "\n",
    "import threading  # threaded process evals\n",
    "\n",
    "from acumos.wrapped import load_model\n",
    "from acumos.modeling import Model, List, Dict, create_namedtuple, create_dataframe\n",
    "from acumos.session import AcumosSession, Requirements\n",
    "\n",
    "import util_call\n",
    "import util_review\n",
    "\n",
    "# load our configuration\n",
    "config_path = 'config.yaml'\n",
    "if not os.path.isfile(config_path):\n",
    "    print(\"Sorry, can't find the configuration file {}, aborting.\".format(config_path))\n",
    "    sys.exit(-1)\n",
    "config = yaml.safe_load(open(config_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Raw Data\n",
    "Load the raw test data and double-check the schema of the data with a random sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['helpful', 'reviewText', 'summary', 'unixReviewTime', 'categories',\n",
      "       'description'],\n",
      "      dtype='object')\n",
      "row_id                                       -2253507452453936056\n",
      "helpful                                                    [0, 1]\n",
      "reviewText      Easy out of the box setup and connection to th...\n",
      "summary                      Great printer, easy to setup and use\n",
      "unixReviewTime                                         1405900800\n",
      "categories                  [office products, office electronics]\n",
      "description                                                      \n"
     ]
    }
   ],
   "source": [
    "## PART 1 - load and start a local model runner \n",
    "# https://pypi.org/project/acumos/#using-dataframes-with-scikit-learn\n",
    "\n",
    "# read our larger datasets as binary files\n",
    "with gzip.open(config[\"path\"][\"etl\"], 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "print(df[\"X_test\"].columns)\n",
    "print(df[\"X_test\"].sample(1).transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create wrapped model protoype\n",
    "Future versions of the API are addressing this issue, but for now, we'll need to mock-up what the call structure looks like for a given model.  For example, check the `Model Prototype Definition` section from the last  notebook for some additional discussion.  \n",
    "\n",
    "*NOTE*: The most natural way to do get a model's signature and connection data is to find it on the marketplace and download the required files (e.g. protobuf definition, etc) from there directly.\n",
    "\n",
    "Looking at a few example models for text-based sentiment processing we see a few common types there as well.\n",
    "\n",
    "* **text-to-float** pattern: a textual string is input for the output of class probabilites\n",
    "> TextIn = create_namedtuple('TextIn', [(\"TextIn\", str)])\n",
    "  FloatOut = create_namedtuple('FloatOut', [(\"FloatOut\", List[float])])\n",
    "\n",
    "* **text-to-float** pattern: a textual string is input for the output of class probabilites\n",
    "> TextIn = create_namedtuple('TextIn', [(\"TextIn\", str)])\n",
    "  FloatOut = create_namedtuple('FloatOut', [(\"FloatOut\", List[float])])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through and create just a few model templates\n",
    "TextIn = create_namedtuple('TextIn', [(\"TextIn\", str)])\n",
    "FloatOut = create_namedtuple('FloatOut', [(\"FloatOut\", List[float])])\n",
    "\n",
    "# create function templates\n",
    "def sent_predict(df: TextIn) -> FloatOut:\n",
    "    '''Dummy function for prediction of a sentice'''\n",
    "    return FloatOut([])\n",
    "model = Model(sent_predict=sent_predict, classify=sent_predict)\n",
    "\n",
    "# create model so that we can run it locally\n",
    "session = AcumosSession()\n",
    "model_dump = config[\"publish\"][\"name_model3\"]+\"_\"+\"text-to-float\"\n",
    "path_dump = os.path.join('data', model_dump)\n",
    "if os.path.exists(path_dump):\n",
    "    shutil.rmtree(path_dump)\n",
    "session.dump(model, model_dump, 'data')  # creates ~/<name_publish>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load & Evaluate a Sentiment Model\n",
    "Now that we have the model prototype \n",
    "\n",
    "1. Iterate through which text models (the shared ones) we want to analyze\n",
    "\n",
    "2. For the raw training data and test data (the places where we have raw textual reviews), convienently wrapped in the helper function `call_sentiment_helper`\n",
    "    1. Load the right stubbed model template (the one we just saved to disk above)\n",
    "    2. Sub-sample the raw input data if a max number of items was provided (this speeds up the local demo)\n",
    "    3. Call our model at a remote URL with the input data\n",
    "    4. Depending on the model template (the call pattern), pull out specific floating values to keep (flatten)\n",
    "    5. Return results\n",
    "\n",
    "3. With the above results, write them to disk if it was a full dataset (because it takes a while) or display them to verify that we're doing the right thing!\n",
    "\n",
    "4. Finally, cooalte the different results from each sentiment processor into a final data dictionary that other notebook scripts can utilize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Started processing for model 'yelp'... === \n",
      "Started processing data... (25374 of 25374 samples)\n",
      "=== Started processing for model 'care'... === \n",
      "Started processing data... (25374 of 25374 samples)\n",
      "=== Started processing for model 'twitter'... === \n",
      "Started processing data... (25374 of 25374 samples)\n"
     ]
    }
   ],
   "source": [
    "# first, we define a helper function that will load a model and call it against data\n",
    "def call_sentiment_helper(model_name, df_eval, col_process, max_process_items, config, wrapped_model=None):\n",
    "    # load model from disk, see that it is a nicely \"wrapped\" model\n",
    "    model_remote_param = config[\"sentiment\"][model_name]\n",
    "    model_dump = config[\"publish\"][\"name_model3\"]+\"_\"+model_remote_param[\"style\"]\n",
    "    \n",
    "    # we allow the model to be passed because (a) they're all the same, (b) threading breaks with sessions\n",
    "    if wrapped_model is None:\n",
    "        wrapped_model = load_model(os.path.join('data', model_dump))\n",
    "\n",
    "    # although there are a few text columns, we'll just send the the column `reviewText` in for analysis\n",
    "    # NOTE: we're \"wrapping\" the one column as well for standard calling structure\n",
    "    #    nd_sample = [ [text1], [text2], ... ]\n",
    "    idx_access = list(range(len(df_eval)))\n",
    "    if max_process_items != 0:   # 0 special case for EVERYTHING\n",
    "        np.random.shuffle(idx_access)\n",
    "        idx_access = idx_access[:min(len(idx_access), max_process_items)]\n",
    "    print(\"Started processing data... ({} of {} samples)\".format(len(idx_access), len(df_eval)))\n",
    "    nd_sample = [[wrap_item] for wrap_item in df_eval.iloc[idx_access][col_process].values.tolist()]\n",
    "    list_result, list_idx = util_call.score_model(wrapped_model, nd_sample, False,\n",
    "                        name_function=model_remote_param[\"api\"],\n",
    "                        url_remote=\"{}:{}\".format(\n",
    "                            config[\"sentiment\"][\"deploy_host\"], model_remote_param[\"port\"]))\n",
    "    index_df = [idx_access[i] for i in list_idx]  # remap our index in case anything was missed!\n",
    "    df_result = pd.DataFrame(list_result, index=df_eval.index[index_df])\n",
    "    # now pull out the iteresting parts according to known style/output\n",
    "    col_new = [\"{}_{}\".format(model_name, c) for c in [col_process]]  # TODO: rework for multi-column?\n",
    "    if model_remote_param[\"style\"] == \"text-to-float\":\n",
    "        df_result = pd.DataFrame(df_result[\"FloatOut\"].values, columns=col_new, index=df_result.index)\n",
    "    # TODO: other styles....\n",
    "        \n",
    "    # looks like yelp_textReview but can be multiple floats ....\n",
    "    col_new = list(df_result.columns)\n",
    "    for c in col_new:\n",
    "        feat_n = len(df_result[c].sample(1))\n",
    "        col_expanded = [\"{}_{:03d}\".format(c, idx) for idx in range(feat_n)]\n",
    "        df_expand = pd.DataFrame(df_result[c].values.tolist(), \n",
    "                          columns=col_expanded, index=df_result.index)        \n",
    "        df_result = df_result.join(df_expand)   # join new expanded columns\n",
    "        del df_result[c]  # delete old singular column\n",
    "    return df_result\n",
    "\n",
    "def helper_thread(model_name, wrapped_model=None):\n",
    "    print(\"=== Started processing for model '{}'... === \".format(model_name))\n",
    "    path_sentiment = config[\"sentiment\"][model_name][\"path\"]\n",
    "    if not os.path.exists(path_sentiment) or max_process_items!=0:  # run training if overall missing or for demo\n",
    "        df_scored = call_sentiment_helper(model_name, df_raw, \n",
    "            sentiment[\"col_sentiment\"], max_process_items, config, wrapped_model=wrapped_model)\n",
    "        if max_process_items==0:    # only write full datasets\n",
    "            df_scored.to_csv(path_sentiment, index=True, header=True)\n",
    "    \n",
    "        # show a preview of what was just done...\n",
    "        print(\"... sample for model '{}'\".format(model_name))\n",
    "        print(df_scored.join(df_raw).sample(3))\n",
    "\n",
    "# okay, let's get ready to call our helper function for requested models\n",
    "sentiment = {}\n",
    "sentiment[\"col_sentiment\"] = \"reviewText\"\n",
    "\n",
    "# truncate range for faster evaluation\n",
    "max_process_items = 10     # set to 0 for everything (warning it might take a while)\n",
    "\n",
    "# actual evaluation code...\n",
    "thread_list = []\n",
    "thread_utilize = True\n",
    "# load model (WARNING: if you needed another model style than what was created, you may need to rework this)\n",
    "wrapped_model = load_model(os.path.join('data', model_dump))\n",
    "df_raw = pd.concat([df[\"X_test\"], df[\"X_train_raw\"]])\n",
    "# evaluate models that are activated/available\n",
    "for model_name in config[\"sentiment\"][\"active_model\"]:\n",
    "    if thread_utilize:       # creating thread\n",
    "        t1 = threading.Thread(target=helper_thread, args=(model_name,wrapped_model)) \n",
    "        t1.start()\n",
    "        thread_list.append(t1)\n",
    "    else:\n",
    "        helper_thread(model_name,wrapped_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 250...\n",
      "Sample 250...\n",
      "Sample 500...\n",
      "Sample 500...\n",
      "Sample 250...\n",
      "Sample 750...\n",
      "Sample 750...\n",
      "Sample 1000...\n",
      "Sample 1000...\n",
      "Output error (http://acumos-gpu.research.att.com:8763), exception (500 Server Error: INTERNAL SERVER ERROR for url: http://acumos-gpu.research.att.com:8763/classify)\n",
      "Sample 500...\n",
      "Sample 1250...\n",
      "Sample 1250...\n",
      "Sample 1500...\n",
      "Sample 1500...\n",
      "Sample 750...\n",
      "Sample 1750...\n",
      "Sample 1750...\n",
      "Sample 2000...\n",
      "Sample 2000...\n",
      "Sample 2250...\n",
      "Sample 1000...\n",
      "Sample 2500...\n",
      "Sample 2250...\n",
      "Sample 2750...\n",
      "Sample 2500...\n",
      "Sample 1250...\n",
      "Sample 3000...\n",
      "Sample 2750...\n",
      "Sample 3250...\n",
      "Sample 3000...\n",
      "Sample 1500...\n",
      "Sample 3500...\n",
      "Sample 3750...\n",
      "Sample 3250...\n",
      "Sample 4000...\n",
      "Sample 1750...\n",
      "Sample 3500...\n",
      "Sample 4250...\n",
      "Sample 3750...\n",
      "Sample 4500...\n",
      "Sample 2000...\n",
      "Sample 4000...\n",
      "Sample 4750...\n",
      "Sample 5000...\n",
      "Sample 4250...\n",
      "Sample 5250...\n",
      "Sample 2250...\n",
      "Sample 4500...\n",
      "Sample 5500...\n",
      "Sample 4750...\n",
      "Sample 5750...\n",
      "Sample 2500...\n",
      "Sample 5000...\n",
      "Sample 6000...\n",
      "Sample 6250...\n",
      "Sample 5250...\n",
      "Sample 2750...\n",
      "Sample 6500...\n",
      "Sample 5500...\n",
      "Sample 6750...\n",
      "Sample 5750...\n",
      "Sample 3000...\n",
      "Sample 7000...\n",
      "Sample 6000...\n",
      "Sample 7250...\n",
      "Sample 7500...\n",
      "Sample 6250...\n",
      "Sample 3250...\n",
      "Sample 7750...\n",
      "Sample 6500...\n",
      "Sample 8000...\n",
      "Sample 3500...\n",
      "Sample 6750...\n",
      "Sample 8250...\n",
      "Sample 7000...\n",
      "Sample 8500...\n",
      "Sample 3750...\n",
      "Sample 8750...\n",
      "Sample 7250...\n",
      "Sample 9000...\n",
      "Sample 7500...\n",
      "Sample 9250...\n",
      "Sample 4000...\n",
      "Sample 7750...\n",
      "Sample 9500...\n",
      "Sample 8000...\n",
      "Sample 9750...\n",
      "Sample 4250...\n",
      "Sample 10000...\n",
      "Sample 8250...\n",
      "Sample 10250...\n",
      "Sample 8500...\n",
      "Sample 4500...\n",
      "Sample 10500...\n",
      "Sample 8750...\n",
      "Sample 10750...\n",
      "Sample 9000...\n",
      "Sample 11000...\n",
      "Sample 4750...\n",
      "Sample 11250...\n",
      "Sample 9250...\n",
      "Sample 11500...\n",
      "Sample 5000...\n",
      "Sample 9500...\n",
      "Sample 11750...\n",
      "Sample 9750...\n",
      "Sample 12000...\n",
      "Sample 5250...\n",
      "Sample 12250...\n",
      "Sample 10000...\n",
      "Sample 12500...\n",
      "Sample 10250...\n",
      "Sample 5500...\n",
      "Sample 12750...\n",
      "Sample 10500...\n",
      "Sample 13000...\n",
      "Output error (http://acumos-gpu.research.att.com:8763), exception (500 Server Error: INTERNAL SERVER ERROR for url: http://acumos-gpu.research.att.com:8763/classify)\n",
      "Sample 10750...\n",
      "Sample 13250...\n",
      "Sample 5750...\n",
      "Sample 13500...\n",
      "Sample 11000...\n",
      "Sample 13750...\n",
      "Sample 11250...\n",
      "Sample 6000...\n",
      "Sample 14000...\n",
      "Sample 11500...\n",
      "Sample 14250...\n",
      "Sample 11750...\n",
      "Sample 6250...\n",
      "Sample 14500...\n",
      "Sample 14750...\n",
      "Sample 12000...\n",
      "Sample 15000...\n",
      "Sample 6500...\n",
      "Sample 12250...\n",
      "Sample 15250...\n",
      "Sample 12500...\n",
      "Sample 15500...\n",
      "Sample 6750...\n",
      "Sample 12750...\n",
      "Sample 15750...\n",
      "Sample 16000...\n",
      "Sample 13000...\n",
      "Sample 7000...\n",
      "Sample 16250...\n",
      "Sample 13250...\n",
      "Sample 16500...\n",
      "Sample 13500...\n",
      "Sample 7250...\n",
      "Sample 16750...\n",
      "Sample 13750...\n",
      "Sample 17000...\n",
      "Sample 17250...\n",
      "Sample 14000...\n",
      "Sample 7500...\n",
      "Sample 17500...\n",
      "Sample 14250...\n",
      "Sample 17750...\n",
      "Output error (http://acumos-gpu.research.att.com:8763), exception (500 Server Error: INTERNAL SERVER ERROR for url: http://acumos-gpu.research.att.com:8763/classify)\n",
      "Sample 14500...\n",
      "Sample 7750...\n",
      "Sample 18000...\n",
      "Sample 14750...\n",
      "Sample 18250...\n",
      "Sample 8000...\n",
      "Sample 18500...\n",
      "Sample 15000...\n",
      "Sample 18750...\n",
      "Sample 15250...\n",
      "Sample 19000...\n",
      "Sample 8250...\n",
      "Sample 15500...\n",
      "Sample 19250...\n",
      "Sample 15750...\n",
      "Sample 19500...\n",
      "Sample 8500...\n",
      "Sample 16000...\n",
      "Sample 19750...\n",
      "Sample 20000...\n",
      "Sample 16250...\n",
      "Sample 8750...\n",
      "Sample 20250...\n",
      "Sample 16500...\n",
      "Sample 20500...\n",
      "Sample 16750...\n",
      "Sample 9000...\n",
      "Sample 20750...\n",
      "Sample 17000...\n",
      "Sample 21000...\n",
      "Sample 21250...\n",
      "Sample 9250...\n",
      "Sample 17250...\n",
      "Sample 21500...\n",
      "Sample 17500...\n",
      "Sample 21750...\n",
      "Sample 9500...\n",
      "Sample 17750...\n",
      "Sample 22000...\n",
      "Sample 18000...\n",
      "Sample 22250...\n",
      "Sample 9750...\n",
      "Sample 22500...\n",
      "Sample 18250...\n",
      "Sample 22750...\n",
      "Sample 18500...\n",
      "Sample 10000...\n",
      "Sample 23000...\n",
      "Sample 18750...\n",
      "Sample 23250...\n",
      "Sample 19000...\n",
      "Sample 23500...\n",
      "Sample 10250...\n",
      "Sample 23750...\n",
      "Sample 19250...\n",
      "Sample 24000...\n",
      "Sample 10500...\n",
      "Sample 19500...\n",
      "Sample 24250...\n",
      "Output error (http://acumos-gpu.research.att.com:8763), exception (500 Server Error: INTERNAL SERVER ERROR for url: http://acumos-gpu.research.att.com:8763/classify)\n",
      "Sample 19750...\n",
      "Sample 24500...\n",
      "Output error (http://acumos-gpu.research.att.com:8763), exception (500 Server Error: INTERNAL SERVER ERROR for url: http://acumos-gpu.research.att.com:8763/classify)\n",
      "Sample 10750...\n",
      "Sample 20000...\n",
      "Sample 24750...\n",
      "Sample 25000...\n",
      "Sample 20250...\n",
      "Sample 25250...\n",
      "Sample 11000...\n",
      "Evaluation time for 25374 items, 340.497 sec\n",
      "Sample 20500...\n",
      "... sample for model 'twitter'\n",
      "                      twitter_reviewText_000   helpful  \\\n",
      "row_id                                                   \n",
      " 2012140098110543217                0.000099    [0, 0]   \n",
      "-7930359191988873938                0.000049    [0, 0]   \n",
      " 1989604330965048779                0.006303  [17, 20]   \n",
      "\n",
      "                                                             reviewText  \\\n",
      "row_id                                                                    \n",
      " 2012140098110543217  Serves me right for not reading the title comp...   \n",
      "-7930359191988873938  Doesn't tear easily and leaves no residue even...   \n",
      " 1989604330965048779  This unit was tested on a Windows 7 Home Premi...   \n",
      "\n",
      "                                                                summary  \\\n",
      "row_id                                                                    \n",
      " 2012140098110543217  I thought it would look nice as a modern piece...   \n",
      "-7930359191988873938                                          A Keeper!   \n",
      " 1989604330965048779  Nice unit, nothing exceptional - Epson's WF254...   \n",
      "\n",
      "                      unixReviewTime  \\\n",
      "row_id                                 \n",
      " 2012140098110543217      1404604800   \n",
      "-7930359191988873938      1313798400   \n",
      " 1989604330965048779      1351123200   \n",
      "\n",
      "                                                             categories  \\\n",
      "row_id                                                                    \n",
      " 2012140098110543217  [office products, office & school supplies, st...   \n",
      "-7930359191988873938  [office products, office & school supplies, de...   \n",
      " 1989604330965048779  [office products, office electronics, printers...   \n",
      "\n",
      "                                                            description  \n",
      "row_id                                                                   \n",
      " 2012140098110543217                                                     \n",
      "-7930359191988873938  Increase your productivity and update your des...  \n",
      " 1989604330965048779                                                     \n",
      "Sample 20750...\n",
      "Sample 11250...\n",
      "Sample 21000...\n",
      "Sample 21250...\n",
      "Sample 11500...\n",
      "Sample 21500...\n",
      "Sample 21750...\n",
      "Sample 11750...\n",
      "Sample 22000...\n",
      "Sample 12000...\n",
      "Sample 22250...\n",
      "Sample 22500...\n",
      "Sample 12250...\n",
      "Sample 22750...\n",
      "Sample 23000...\n",
      "Sample 12500...\n",
      "Sample 23250...\n",
      "Sample 23500...\n",
      "Sample 12750...\n",
      "Sample 23750...\n",
      "Sample 24000...\n",
      "Sample 13000...\n",
      "Sample 24250...\n",
      "Sample 24500...\n",
      "Sample 13250...\n",
      "Sample 24750...\n",
      "Sample 13500...\n",
      "Sample 25000...\n",
      "Sample 25250...\n",
      "Evaluation time for 25374 items, 425.475 sec\n",
      "Sample 13750...\n",
      "... sample for model 'yelp'\n",
      "                      yelp_reviewText_000 helpful  \\\n",
      "row_id                                              \n",
      "-3377173100368161058         1.328453e-33  [6, 7]   \n",
      "-113164452725297157          7.805266e-03  [4, 4]   \n",
      "-2405497017518951476         5.533625e-03  [0, 0]   \n",
      "\n",
      "                                                             reviewText  \\\n",
      "row_id                                                                    \n",
      "-3377173100368161058  I was very excited to find this product becaus...   \n",
      "-113164452725297157   This is nice, large, heavy unit that stays put...   \n",
      "-2405497017518951476  These post it labels are easy to run through t...   \n",
      "\n",
      "                                                                summary  \\\n",
      "row_id                                                                    \n",
      "-3377173100368161058  Product itself is great, but creating labels c...   \n",
      "-113164452725297157                 Nice...saving me $$$ in art pencils   \n",
      "-2405497017518951476                                 Works as intended.   \n",
      "\n",
      "                      unixReviewTime  \\\n",
      "row_id                                 \n",
      "-3377173100368161058      1322438400   \n",
      "-113164452725297157       1306972800   \n",
      "-2405497017518951476      1265760000   \n",
      "\n",
      "                                                             categories  \\\n",
      "row_id                                                                    \n",
      "-3377173100368161058  [office products, office & school supplies, la...   \n",
      "-113164452725297157   [office products, office & school supplies, wr...   \n",
      "-2405497017518951476  [office products, office & school supplies, st...   \n",
      "\n",
      "                                                            description  \n",
      "row_id                                                                   \n",
      "-3377173100368161058                                                     \n",
      "-113164452725297157                                                      \n",
      "-2405497017518951476  Post-it Super Sticky Color-Coding Labels stick...  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 14000...\n",
      "Sample 14250...\n",
      "Sample 14500...\n",
      "Sample 14750...\n",
      "Output error (http://acumos-gpu.research.att.com:8763), exception (500 Server Error: INTERNAL SERVER ERROR for url: http://acumos-gpu.research.att.com:8763/classify)\n",
      "Sample 15000...\n",
      "Sample 15250...\n",
      "Sample 15500...\n",
      "Sample 15750...\n",
      "Sample 16000...\n",
      "Sample 16250...\n",
      "Sample 16500...\n",
      "Sample 16750...\n",
      "Sample 17000...\n",
      "Sample 17250...\n",
      "Sample 17500...\n",
      "Sample 17750...\n",
      "Sample 18000...\n",
      "Sample 18250...\n",
      "Sample 18500...\n",
      "Sample 18750...\n",
      "Sample 19000...\n",
      "Sample 19250...\n",
      "Sample 19500...\n",
      "Sample 19750...\n",
      "Sample 20000...\n",
      "Sample 20250...\n",
      "Sample 20500...\n",
      "Sample 20750...\n",
      "Sample 21000...\n",
      "Sample 21250...\n",
      "Sample 21500...\n",
      "Sample 21750...\n",
      "Sample 22000...\n",
      "Sample 22250...\n",
      "Sample 22500...\n",
      "Sample 22750...\n",
      "Output error (http://acumos-gpu.research.att.com:8763), exception (500 Server Error: INTERNAL SERVER ERROR for url: http://acumos-gpu.research.att.com:8763/classify)\n",
      "Sample 23000...\n",
      "Sample 23250...\n",
      "Sample 23500...\n",
      "Sample 23750...\n",
      "Sample 24000...\n",
      "Sample 24250...\n",
      "Sample 24500...\n",
      "Sample 24750...\n",
      "Sample 25000...\n",
      "Sample 25250...\n",
      "Evaluation time for 25374 items, 840.801 sec\n",
      "... sample for model 'care'\n",
      "                      care_reviewText_000 helpful  \\\n",
      "row_id                                              \n",
      " 885990454741508362              0.674092  [1, 2]   \n",
      "-7209008690714166879             0.690087  [0, 0]   \n",
      "-998237321857384140              0.723309  [1, 1]   \n",
      "\n",
      "                                                             reviewText  \\\n",
      "row_id                                                                    \n",
      " 885990454741508362   I selected these because i started my own busi...   \n",
      "-7209008690714166879  The pen has an attractive appearance.  At firs...   \n",
      "-998237321857384140   I have a small business in entertainment, and ...   \n",
      "\n",
      "                                     summary  unixReviewTime  \\\n",
      "row_id                                                         \n",
      " 885990454741508362             Fun and easy      1359590400   \n",
      "-7209008690714166879      A nice looking pen      1387411200   \n",
      "-998237321857384140   Great home office tool      1397001600   \n",
      "\n",
      "                                                             categories  \\\n",
      "row_id                                                                    \n",
      " 885990454741508362   [office products, office & school supplies, la...   \n",
      "-7209008690714166879  [office products, office & school supplies, wr...   \n",
      "-998237321857384140   [office products, office & school supplies, pr...   \n",
      "\n",
      "                                                            description  \n",
      "row_id                                                                   \n",
      " 885990454741508362                                                      \n",
      "-7209008690714166879                                                     \n",
      "-998237321857384140   This versatile 4-month, dry-erase calendar is ...  \n"
     ]
    }
   ],
   "source": [
    "# wait for all threads to terminate\n",
    "for i in range(len(thread_list)):\n",
    "    thread_list[i].join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining and writing combined features to output ETL file...\n",
      "Model 'yelp' read sentiment dimensions (25374, 1)\n",
      "Model 'care' read sentiment dimensions (25367, 1)\n",
      "Model 'twitter' read sentiment dimensions (25374, 1)\n",
      "Combined training dimensions (20299, 3), test dimensions (5075, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Combining and writing combined features to output ETL file...\")\n",
    "sentiment[\"X_test\"] = pd.DataFrame([], index=df[\"X_test\"].index)\n",
    "sentiment[\"X_train\"] = pd.DataFrame([], index=df[\"X_train_raw\"].index)\n",
    "\n",
    "# now read the processed samples into our main dataframe\n",
    "for model_name in config[\"sentiment\"][\"active_model\"]:\n",
    "    path_sentiment = config[\"sentiment\"][model_name][\"path\"]\n",
    "    if os.path.exists(path_sentiment):\n",
    "        df_read = pd.read_csv(path_sentiment, index_col=\"row_id\")\n",
    "        sentiment[\"X_train\"] = sentiment[\"X_train\"].join(df_read).fillna(0)\n",
    "        sentiment[\"X_test\"] = sentiment[\"X_test\"].join(df_read).fillna(0)\n",
    "        print(\"Model '{}' read sentiment dimensions {}\".format(model_name, df_read.shape))\n",
    "                \n",
    "print(\"Combined training dimensions {}, test dimensions {}\".format(sentiment[\"X_train\"].shape, sentiment[\"X_test\"].shape))\n",
    "with gzip.open(config[\"path\"][\"sentiment\"], 'wb') as f:\n",
    "    pickle.dump(sentiment, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
