{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of simple model load and evaluate\n",
    "\n",
    "# ===============LICENSE_START=======================================================\n",
    "# Apache-2.0\n",
    "# ===================================================================================\n",
    "# Copyright (C) 2019 AT&T Intellectual Property  All rights reserved.\n",
    "# ===================================================================================\n",
    "# This software file is distributed by AT&T\n",
    "# under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# This file is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ===============LICENSE_END=========================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,sys,shutil  # file checks\n",
    "import dill as pickle   # serialize functions and data as compressed binary \n",
    "import gzip  # compression \n",
    "import yaml   # configuration file\n",
    "import time  # time tracking\n",
    "\n",
    "import threading  # threaded process evals\n",
    "\n",
    "from acumos.wrapped import load_model\n",
    "from acumos.modeling import Model, List, Dict, create_namedtuple, create_dataframe\n",
    "from acumos.session import AcumosSession, Requirements\n",
    "\n",
    "import util_call\n",
    "import util_review\n",
    "\n",
    "# load our configuration\n",
    "config_path = 'config.yaml'\n",
    "if not os.path.isfile(config_path):\n",
    "    print(\"Sorry, can't find the configuration file {}, aborting.\".format(config_path))\n",
    "    sys.exit(-1)\n",
    "config = yaml.safe_load(open(config_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Raw Data\n",
    "Load the raw test data and double-check the schema of the data with a random sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['helpful', 'reviewText', 'summary', 'unixReviewTime', 'categories',\n",
      "       'description'],\n",
      "      dtype='object')\n",
      "row_id                                                      13428\n",
      "helpful                                                    [0, 0]\n",
      "reviewText      We have a lot of family who live in other stat...\n",
      "summary                                           Perfect Mailers\n",
      "unixReviewTime                                         1332201600\n",
      "categories      [office products, office & school supplies, en...\n",
      "description     The Gift-e-lope is a pre-constructed, mailable...\n"
     ]
    }
   ],
   "source": [
    "## PART 1 - load and start a local model runner \n",
    "# https://pypi.org/project/acumos/#using-dataframes-with-scikit-learn\n",
    "\n",
    "# read our larger datasets as binary files\n",
    "with gzip.open(config[\"path\"][\"etl\"], 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "print(df[\"X_test\"].columns)\n",
    "print(df[\"X_test\"].sample(1).transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create wrapped model protoype\n",
    "Future versions of the API are addressing this issue, but for now, we'll need to mock-up what the call structure looks like for a given model.  For example, check the `Model Prototype Definition` section from the last  notebook for some additional discussion.  \n",
    "\n",
    "*NOTE*: The most natural way to do get a model's signature and connection data is to find it on the marketplace and download the required files (e.g. protobuf definition, etc) from there directly.\n",
    "\n",
    "Looking at a few example models for text-based sentiment processing we see a few common types there as well.\n",
    "\n",
    "* **text-to-float** pattern: a textual string is input for the output of class probabilites\n",
    "> TextIn = create_namedtuple('TextIn', [(\"TextIn\", str)])\n",
    "  FloatOut = create_namedtuple('FloatOut', [(\"FloatOut\", List[float])])\n",
    "\n",
    "* **text-to-float** pattern: a textual string is input for the output of class probabilites\n",
    "> TextIn = create_namedtuple('TextIn', [(\"TextIn\", str)])\n",
    "  FloatOut = create_namedtuple('FloatOut', [(\"FloatOut\", List[float])])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through and create just a few model templates\n",
    "TextIn = create_namedtuple('TextIn', [(\"TextIn\", str)])\n",
    "FloatOut = create_namedtuple('FloatOut', [(\"FloatOut\", List[float])])\n",
    "\n",
    "# create function templates\n",
    "def sent_predict(df: TextIn) -> FloatOut:\n",
    "    '''Dummy function for prediction of a sentice'''\n",
    "    return FloatOut([])\n",
    "model = Model(sent_predict=sent_predict, classify=sent_predict)\n",
    "\n",
    "# create model so that we can run it locally\n",
    "session = AcumosSession()\n",
    "model_dump = config[\"publish\"][\"name_model3\"]+\"_\"+\"text-to-float\"\n",
    "path_dump = os.path.join('data', model_dump)\n",
    "if os.path.exists(path_dump):\n",
    "    shutil.rmtree(path_dump)\n",
    "session.dump(model, model_dump, 'data')  # creates ~/<name_publish>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load & Evaluate a Sentiment Model\n",
    "Now that we have the model prototype \n",
    "\n",
    "1. Iterate through which text models (the shared ones) we want to analyze\n",
    "\n",
    "2. For the raw training data and test data (the places where we have raw textual reviews), convienently wrapped in the helper function `call_sentiment_helper`\n",
    "    1. Load the right stubbed model template (the one we just saved to disk above)\n",
    "    2. Sub-sample the raw input data if a max number of items was provided (this speeds up the local demo)\n",
    "    3. Call our model at a remote URL with the input data\n",
    "    4. Depending on the model template (the call pattern), pull out specific floating values to keep (flatten)\n",
    "    5. Return results\n",
    "\n",
    "3. With the above results, write them to disk if it was a full dataset (because it takes a while) or display them to verify that we're doing the right thing!\n",
    "\n",
    "4. Finally, cooalte the different results from each sentiment processor into a final data dictionary that other notebook scripts can utilize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Started processing for model 'yelp'... === \n",
      "Started processing data... (5075 of 5075 samples)\n",
      "=== Started processing for model 'care'... === \n",
      "=== Started processing for model 'twitter'... === \n",
      "Started processing data... (5075 of 5075 samples)\n",
      "Started processing data... (5075 of 5075 samples)\n"
     ]
    }
   ],
   "source": [
    "# first, we define a helper function that will load a model and call it against data\n",
    "def call_sentiment_helper(model_name, df_eval, col_process, max_process_items, config, wrapped_model=None):\n",
    "    # load model from disk, see that it is a nicely \"wrapped\" model\n",
    "    model_remote_param = config[\"sentiment\"][model_name]\n",
    "    model_dump = config[\"publish\"][\"name_model3\"]+\"_\"+model_remote_param[\"style\"]\n",
    "    \n",
    "    # we allow the model to be passed because (a) they're all the same, (b) threading breaks with sessions\n",
    "    if wrapped_model is None:\n",
    "        wrapped_model = load_model(os.path.join('data', model_dump))\n",
    "\n",
    "    # although there are a few text columns, we'll just send the the column `reviewText` in for analysis\n",
    "    # NOTE: we're \"wrapping\" the one column as well for standard calling structure\n",
    "    #    nd_sample = [ [text1], [text2], ... ]\n",
    "    idx_access = list(range(len(df_eval)))\n",
    "    if max_process_items != 0:   # 0 special case for EVERYTHING\n",
    "        np.random.shuffle(idx_access)\n",
    "        idx_access = idx_access[:min(len(idx_access), max_process_items)]\n",
    "    print(\"Started processing data... ({} of {} samples)\".format(len(idx_access), len(df_eval)))\n",
    "    nd_sample = [[wrap_item] for wrap_item in df_eval.iloc[idx_access][col_process].values.tolist()]\n",
    "    list_result, list_idx = util_call.score_model(wrapped_model, nd_sample, False,\n",
    "                        name_function=model_remote_param[\"api\"],\n",
    "                        url_remote=\"{}:{}\".format(\n",
    "                            config[\"sentiment\"][\"deploy_host\"], model_remote_param[\"port\"]))\n",
    "    index_df = [idx_access[i] for i in list_idx]  # remap our index in case anything was missed!\n",
    "    df_result = pd.DataFrame(list_result, index=df_eval.index[index_df])\n",
    "    # now pull out the iteresting parts according to known style/output\n",
    "    col_new = [\"{}_{}\".format(model_name, c) for c in [col_process]]  # TODO: rework for multi-column?\n",
    "    if model_remote_param[\"style\"] == \"text-to-float\":\n",
    "        df_result = pd.DataFrame(df_result[\"FloatOut\"].values, columns=col_new, index=df_result.index)\n",
    "    # TODO: other styles....\n",
    "        \n",
    "    # looks like yelp_textReview but can be multiple floats ....\n",
    "    col_new = list(df_result.columns)\n",
    "    for c in col_new:\n",
    "        feat_n = len(df_result[c].sample(1))\n",
    "        col_expanded = [\"{}_{:03d}\".format(c, idx) for idx in range(feat_n)]\n",
    "        df_expand = pd.DataFrame(df_result[c].values.tolist(), \n",
    "                          columns=col_expanded, index=df_result.index)        \n",
    "        df_result = df_result.join(df_expand)   # join new expanded columns\n",
    "        del df_result[c]  # delete old singular column\n",
    "    return df_result\n",
    "\n",
    "def helper_thread(model_name, wrapped_model=None):\n",
    "    print(\"=== Started processing for model '{}'... === \".format(model_name))\n",
    "    path_train = config[\"sentiment\"][model_name][\"path\"].format(\"train\")\n",
    "    path_test = config[\"sentiment\"][model_name][\"path\"].format(\"test\")\n",
    "    if not os.path.exists(path_test):  # only run test if overall file is missing\n",
    "        df_test = call_sentiment_helper(model_name, df[\"X_test\"], \n",
    "            sentiment[\"col_sentiment\"], max_process_items, config, wrapped_model=wrapped_model)\n",
    "        if max_process_items==0:    # only write full datasets\n",
    "            df_test.to_csv(path_test, index=True, header=True)\n",
    "    if not os.path.exists(path_train) or max_process_items!=0:  # run training if overall missing or for demo\n",
    "        df_train = call_sentiment_helper(model_name, df[\"X_train_raw\"], \n",
    "            sentiment[\"col_sentiment\"], max_process_items, config, wrapped_model=wrapped_model)\n",
    "        if max_process_items==0:    # only write full datasets\n",
    "            df_train.to_csv(path_train, index=True, header=True)\n",
    "    \n",
    "        # show a preview of what was just done...\n",
    "        print(\"... sample for model '{}'\".format(model_name))\n",
    "        print(df_train.join(df[\"X_train_raw\"]).sample(3))\n",
    "\n",
    "# okay, let's get ready to call our helper function for requested models\n",
    "sentiment = {}\n",
    "sentiment[\"col_sentiment\"] = \"reviewText\"\n",
    "\n",
    "# truncate range for faster evaluation\n",
    "max_process_items = 10     # set to 0 for everything (warning it might take a while)\n",
    "\n",
    "# actual evaluation code...\n",
    "thread_list = []\n",
    "thread_utilize = True\n",
    "# load model (WARNING: if you needed another model style than what was created, you may need to rework this)\n",
    "wrapped_model = load_model(os.path.join('data', model_dump))\n",
    "# evaluate models that are activated/available\n",
    "for model_name in config[\"sentiment\"][\"active_model\"]:\n",
    "    if thread_utilize:       # creating thread\n",
    "        t1 = threading.Thread(target=helper_thread, args=(model_name,wrapped_model)) \n",
    "        t1.start()\n",
    "        thread_list.append(t1)\n",
    "    else:\n",
    "        helper_thread(model_name,wrapped_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 250...\n",
      "Sample 250...\n",
      "Sample 500...\n",
      "Sample 250...\n",
      "Sample 500...\n",
      "Sample 750...\n",
      "Sample 750...\n",
      "Sample 1000...\n",
      "Output error (http://acumos-gpu.research.att.com:8763), exception (500 Server Error: INTERNAL SERVER ERROR for url: http://acumos-gpu.research.att.com:8763/classify)\n",
      "Sample 500...\n",
      "Sample 1250...\n",
      "Sample 1000...\n",
      "Sample 1500...\n",
      "Sample 1250...\n",
      "Sample 750...\n",
      "Sample 1750...\n",
      "Sample 1500...\n",
      "Sample 2000...\n",
      "Sample 1750...\n",
      "Sample 2250...\n",
      "Sample 1000...\n",
      "Sample 2500...\n",
      "Sample 2000...\n",
      "Sample 2750...\n",
      "Sample 2250...\n",
      "Sample 1250...\n",
      "Sample 3000...\n",
      "Sample 2500...\n",
      "Sample 3250...\n",
      "Sample 1500...\n",
      "Sample 2750...\n",
      "Sample 3500...\n",
      "Sample 3750...\n",
      "Sample 3000...\n",
      "Sample 1750...\n",
      "Sample 4000...\n",
      "Sample 3250...\n",
      "Sample 4250...\n",
      "Sample 3500...\n",
      "Sample 4500...\n",
      "Sample 2000...\n",
      "Sample 3750...\n",
      "Sample 4750...\n",
      "Sample 5000...\n",
      "Sample 4000...\n",
      "Evaluation time for 5075 items, 69.317 sec\n",
      "Started processing data... (20299 of 20299 samples)\n",
      "Sample 2250...\n",
      "Sample 250...\n",
      "Sample 4250...\n",
      "Sample 500...\n",
      "Sample 4500...\n",
      "Sample 2500...\n",
      "Sample 750...\n",
      "Sample 4750...\n",
      "Sample 1000...\n",
      "Sample 2750...\n",
      "Sample 5000...\n",
      "Sample 1250...\n",
      "Evaluation time for 5075 items, 86.636 sec\n",
      "Started processing data... (20299 of 20299 samples)\n",
      "Sample 1500...\n",
      "Sample 250...\n",
      "Sample 3000...\n",
      "Sample 1750...\n",
      "Sample 500...\n",
      "Sample 2000...\n",
      "Sample 750...\n",
      "Sample 2250...\n",
      "Sample 3250...\n",
      "Sample 2500...\n",
      "Sample 1000...\n",
      "Sample 2750...\n",
      "Sample 3500...\n",
      "Sample 1250...\n",
      "Sample 3000...\n",
      "Sample 1500...\n",
      "Sample 3250...\n",
      "Sample 3750...\n",
      "Sample 1750...\n",
      "Sample 3500...\n",
      "Sample 3750...\n",
      "Sample 2000...\n",
      "Sample 4000...\n",
      "Sample 4000...\n",
      "Sample 2250...\n",
      "Sample 4250...\n",
      "Sample 2500...\n",
      "Sample 4500...\n",
      "Sample 4250...\n",
      "Sample 4750...\n",
      "Sample 2750...\n",
      "Sample 5000...\n",
      "Sample 3000...\n",
      "Sample 4500...\n",
      "Sample 5250...\n",
      "Sample 3250...\n",
      "Sample 5500...\n",
      "Sample 4750...\n",
      "Sample 3500...\n",
      "Sample 5750...\n",
      "Sample 6000...\n",
      "Sample 3750...\n",
      "Sample 5000...\n",
      "Sample 6250...\n",
      "Sample 4000...\n",
      "Evaluation time for 5075 items, 153.707 sec\n",
      "Started processing data... (20299 of 20299 samples)\n",
      "Sample 6500...\n",
      "Sample 4250...\n",
      "Sample 6750...\n",
      "Sample 4500...\n",
      "Sample 250...\n",
      "Sample 7000...\n",
      "Sample 7250...\n",
      "Sample 4750...\n",
      "Sample 7500...\n",
      "Sample 500...\n",
      "Sample 5000...\n",
      "Output error (http://acumos-gpu.research.att.com:8763), exception (500 Server Error: INTERNAL SERVER ERROR for url: http://acumos-gpu.research.att.com:8763/classify)\n",
      "Sample 7750...\n",
      "Sample 5250...\n",
      "Sample 8000...\n",
      "Sample 750...\n",
      "Sample 5500...\n",
      "Sample 8250...\n",
      "Sample 8500...\n",
      "Sample 5750...\n",
      "Sample 1000...\n",
      "Sample 8750...\n",
      "Sample 6000...\n",
      "Sample 9000...\n",
      "Sample 6250...\n",
      "Sample 9250...\n",
      "Sample 1250...\n",
      "Sample 6500...\n",
      "Sample 9500...\n",
      "Sample 9750...\n",
      "Sample 6750...\n",
      "Sample 1500...\n",
      "Sample 10000...\n",
      "Sample 7000...\n",
      "Sample 10250...\n",
      "Sample 1750...\n",
      "Sample 7250...\n",
      "Sample 10500...\n",
      "Sample 7500...\n",
      "Sample 10750...\n",
      "Sample 2000...\n",
      "Sample 11000...\n",
      "Sample 7750...\n",
      "Sample 11250...\n",
      "Sample 8000...\n",
      "Sample 11500...\n",
      "Sample 2250...\n",
      "Sample 8250...\n",
      "Sample 11750...\n",
      "Sample 8500...\n",
      "Sample 12000...\n",
      "Sample 2500...\n",
      "Sample 8750...\n",
      "Sample 12250...\n",
      "Output error (http://acumos-gpu.research.att.com:8763), exception (500 Server Error: INTERNAL SERVER ERROR for url: http://acumos-gpu.research.att.com:8763/classify)\n",
      "Sample 12500...\n",
      "Sample 9000...\n",
      "Sample 2750...\n",
      "Sample 12750...\n",
      "Sample 9250...\n",
      "Sample 13000...\n",
      "Sample 9500...\n",
      "Sample 3000...\n",
      "Sample 13250...\n",
      "Sample 13500...\n",
      "Sample 9750...\n",
      "Sample 13750...\n",
      "Sample 3250...\n",
      "Sample 10000...\n",
      "Sample 14000...\n",
      "Sample 10250...\n",
      "Sample 14250...\n",
      "Sample 3500...\n",
      "Sample 10500...\n",
      "Sample 14500...\n",
      "Sample 10750...\n",
      "Sample 14750...\n",
      "Sample 3750...\n",
      "Sample 15000...\n",
      "Sample 11000...\n",
      "Sample 15250...\n",
      "Sample 11250...\n",
      "Sample 4000...\n",
      "Sample 15500...\n",
      "Sample 11500...\n",
      "Sample 15750...\n",
      "Sample 4250...\n",
      "Sample 11750...\n",
      "Sample 16000...\n",
      "Sample 16250...\n",
      "Sample 12000...\n",
      "Sample 16500...\n",
      "Sample 4500...\n",
      "Sample 12250...\n",
      "Sample 16750...\n",
      "Sample 12500...\n",
      "Sample 17000...\n",
      "Sample 4750...\n",
      "Sample 12750...\n",
      "Sample 17250...\n",
      "Sample 17500...\n",
      "Sample 13000...\n",
      "Sample 5000...\n",
      "Sample 17750...\n",
      "Sample 13250...\n",
      "Sample 18000...\n",
      "Sample 13500...\n",
      "Sample 5250...\n",
      "Sample 18250...\n",
      "Sample 13750...\n",
      "Sample 18500...\n",
      "Sample 18750...\n",
      "Output error (http://acumos-gpu.research.att.com:8763), exception (500 Server Error: INTERNAL SERVER ERROR for url: http://acumos-gpu.research.att.com:8763/classify)\n",
      "Sample 5500...\n",
      "Sample 14000...\n",
      "Sample 19000...\n",
      "Output error (http://acumos-gpu.research.att.com:8763), exception (500 Server Error: INTERNAL SERVER ERROR for url: http://acumos-gpu.research.att.com:8763/classify)\n",
      "Sample 14250...\n",
      "Sample 19250...\n",
      "Sample 5750...\n",
      "Sample 14500...\n",
      "Sample 19500...\n",
      "Sample 19750...\n",
      "Sample 14750...\n",
      "Sample 6000...\n",
      "Sample 20000...\n",
      "Sample 15000...\n",
      "Sample 20250...\n",
      "Evaluation time for 20299 items, 266.652 sec\n",
      "... sample for model 'twitter'\n",
      "        twitter_reviewText_000 helpful  \\\n",
      "row_id                                   \n",
      "13042             2.359095e-03  [2, 2]   \n",
      "712               1.467742e-09  [0, 0]   \n",
      "8594              1.098134e-05  [1, 1]   \n",
      "\n",
      "                                               reviewText  \\\n",
      "row_id                                                      \n",
      "13042   I like the chair, but if you're super short or...   \n",
      "712     This is a plastic Guillotine from Swingline. A...   \n",
      "8594    First, these little tabs are not that little -...   \n",
      "\n",
      "                                                  summary  unixReviewTime  \\\n",
      "row_id                                                                      \n",
      "13042   How to measure your size for this chair. Not f...      1359763200   \n",
      "712                         Great guillotine, works great      1392595200   \n",
      "8594                  Superior quality, does the job well      1260748800   \n",
      "\n",
      "                                               categories  \\\n",
      "row_id                                                      \n",
      "13042   [office products, office furniture & lighting,...   \n",
      "712     [office products, office & school supplies, cu...   \n",
      "8594    [office products, office & school supplies, la...   \n",
      "\n",
      "                                              description  \n",
      "row_id                                                     \n",
      "13042                                                      \n",
      "712                                                        \n",
      "8594    Organize your work, your way - with Avery Note...  \n",
      "Sample 15250...\n",
      "Sample 6250...\n",
      "Sample 15500...\n",
      "Sample 15750...\n",
      "Sample 6500...\n",
      "Sample 16000...\n",
      "Sample 6750...\n",
      "Sample 16250...\n",
      "Sample 16500...\n",
      "Sample 7000...\n",
      "Sample 16750...\n",
      "Sample 17000...\n",
      "Sample 7250...\n",
      "Sample 17250...\n",
      "Sample 17500...\n",
      "Sample 7500...\n",
      "Sample 17750...\n",
      "Sample 18000...\n",
      "Sample 7750...\n",
      "Sample 18250...\n",
      "Sample 8000...\n",
      "Sample 18500...\n",
      "Sample 18750...\n",
      "Sample 8250...\n",
      "Sample 19000...\n",
      "Sample 19250...\n",
      "Sample 8500...\n",
      "Sample 19500...\n",
      "Sample 19750...\n",
      "Sample 8750...\n",
      "Sample 20000...\n",
      "Sample 20250...\n",
      "Sample 9000...\n",
      "Evaluation time for 20299 items, 338.810 sec\n",
      "... sample for model 'yelp'\n",
      "        yelp_reviewText_000 helpful  \\\n",
      "row_id                                \n",
      "5170               0.007812  [1, 1]   \n",
      "11359              0.003954  [0, 0]   \n",
      "19167              0.007063  [3, 4]   \n",
      "\n",
      "                                               reviewText  \\\n",
      "row_id                                                      \n",
      "5170    I purchased theScotch Thermal Laminator Combo ...   \n",
      "11359   Nice sharp lines, ink is dark and easy to read...   \n",
      "19167   This is an amazing system!  It's like having a...   \n",
      "\n",
      "                                    summary  unixReviewTime  \\\n",
      "row_id                                                        \n",
      "5170    A quality product at a great price!      1352851200   \n",
      "11359                                Great!      1314835200   \n",
      "19167               Amazing!!! Does it ALL!      1352851200   \n",
      "\n",
      "                                               categories  \\\n",
      "row_id                                                      \n",
      "5170    [office products, office electronics, presenta...   \n",
      "11359   [office products, office & school supplies, wr...   \n",
      "19167   [office products, office electronics, printers...   \n",
      "\n",
      "                                              description  \n",
      "row_id                                                     \n",
      "5170                                                       \n",
      "11359   BIC Great Erase Grip \"Pocket\" Dry Erase Marker...  \n",
      "19167                                                      \n",
      "Sample 9250...\n",
      "Sample 9500...\n",
      "Sample 9750...\n",
      "Output error (http://acumos-gpu.research.att.com:8763), exception (500 Server Error: INTERNAL SERVER ERROR for url: http://acumos-gpu.research.att.com:8763/classify)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 10000...\n",
      "Sample 10250...\n",
      "Sample 10500...\n",
      "Sample 10750...\n",
      "Sample 11000...\n",
      "Sample 11250...\n",
      "Sample 11500...\n",
      "Sample 11750...\n",
      "Sample 12000...\n",
      "Sample 12250...\n",
      "Sample 12500...\n",
      "Sample 12750...\n",
      "Sample 13000...\n",
      "Sample 13250...\n",
      "Sample 13500...\n",
      "Sample 13750...\n",
      "Sample 14000...\n",
      "Sample 14250...\n",
      "Sample 14500...\n",
      "Sample 14750...\n",
      "Sample 15000...\n",
      "Sample 15250...\n",
      "Sample 15500...\n",
      "Sample 15750...\n",
      "Sample 16000...\n",
      "Sample 16250...\n",
      "Sample 16500...\n",
      "Sample 16750...\n",
      "Sample 17000...\n",
      "Sample 17250...\n",
      "Sample 17500...\n",
      "Output error (http://acumos-gpu.research.att.com:8763), exception (500 Server Error: INTERNAL SERVER ERROR for url: http://acumos-gpu.research.att.com:8763/classify)\n",
      "Sample 17750...\n",
      "Sample 18000...\n",
      "Sample 18250...\n",
      "Sample 18500...\n",
      "Sample 18750...\n",
      "Sample 19000...\n",
      "Sample 19250...\n",
      "Sample 19500...\n",
      "Sample 19750...\n",
      "Sample 20000...\n",
      "Sample 20250...\n",
      "Evaluation time for 20299 items, 683.656 sec\n",
      "... sample for model 'care'\n",
      "        care_reviewText_000 helpful  \\\n",
      "row_id                                \n",
      "24834              0.278550  [0, 0]   \n",
      "15899              0.475931  [0, 0]   \n",
      "10470              0.839481  [0, 0]   \n",
      "\n",
      "                                               reviewText  \\\n",
      "row_id                                                      \n",
      "24834   Built like a tank.  I have a cheap Scotch lami...   \n",
      "15899   First let me say that I ordered this tool expe...   \n",
      "10470   These Swingline Retractable Badge Reel are gre...   \n",
      "\n",
      "                           summary  unixReviewTime  \\\n",
      "row_id                                               \n",
      "24834   Fast and solid like a tank      1404691200   \n",
      "15899    Does more than I expected      1311638400   \n",
      "10470                Great product      1402531200   \n",
      "\n",
      "                                               categories  \\\n",
      "row_id                                                      \n",
      "24834   [office products, office electronics, presenta...   \n",
      "15899   [office products, office & school supplies, cu...   \n",
      "10470   [office products, office & school supplies, la...   \n",
      "\n",
      "                                              description  \n",
      "row_id                                                     \n",
      "24834                                                      \n",
      "15899   The Scotch Safe Cut Package Opener is designed...  \n",
      "10470   Translucent badge reel with 3 feet of retracta...  \n"
     ]
    }
   ],
   "source": [
    "# wait for all threads to terminate\n",
    "for i in range(len(thread_list)):\n",
    "    thread_list[i].join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining and writing combined features to output ETL file...\n",
      "Model 'yelp' training dimensions (20299, 1), test dimensions (20299, 1)\n",
      "Model 'care' training dimensions (20293, 1), test dimensions (20293, 1)\n",
      "Model 'twitter' training dimensions (20299, 1), test dimensions (20299, 1)\n",
      "Combined training dimensions (20299, 3), test dimensions (5075, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Combining and writing combined features to output ETL file...\")\n",
    "sentiment[\"X_test\"] = pd.DataFrame([], index=df[\"X_test\"].index)\n",
    "sentiment[\"X_train\"] = pd.DataFrame([], index=df[\"X_train_raw\"].index)\n",
    "\n",
    "# now read the processed samples into our main dataframe\n",
    "for model_name in config[\"sentiment\"][\"active_model\"]:\n",
    "    path_train = config[\"sentiment\"][model_name][\"path\"].format(\"train\")\n",
    "    path_test = config[\"sentiment\"][model_name][\"path\"].format(\"test\")\n",
    "    if os.path.exists(path_train) and os.path.exists(path_test):\n",
    "        df_read = pd.read_csv(path_train, index_col=\"row_id\")\n",
    "        shape_train = df_read.shape\n",
    "        sentiment[\"X_train\"] = sentiment[\"X_train\"].join(df_read).fillna(0)\n",
    "        df_read = pd.read_csv(path_train, index_col=\"row_id\")\n",
    "        shape_test = df_read.shape\n",
    "        sentiment[\"X_test\"] = sentiment[\"X_test\"].join(df_read).fillna(0)\n",
    "        print(\"Model '{}' training dimensions {}, test dimensions {}\".format(model_name, shape_train, shape_test))\n",
    "                \n",
    "print(\"Combined training dimensions {}, test dimensions {}\".format(sentiment[\"X_train\"].shape, sentiment[\"X_test\"].shape))\n",
    "with gzip.open(config[\"path\"][\"sentiment\"], 'wb') as f:\n",
    "    pickle.dump(sentiment, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
